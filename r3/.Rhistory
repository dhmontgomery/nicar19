knitr::opts_chunk$set(echo = TRUE)
donotcall <- read_csv("https://www.ftc.gov/sites/default/files/dnc_complaint_numbers_2018-07-02-06.csv")
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
donotcall <- read_csv("https://www.ftc.gov/sites/default/files/dnc_complaint_numbers_2018-07-02-06.csv")
library(tidyverse) # All sorts of vital tools
library(scales) # Helps make our ggplot graphs prettier
library(stringr) # Tools for cleaning up text
library(rvest) # Tools for scraping
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse) # All sorts of vital tools
library(scales) # Helps make our ggplot graphs prettier
library(stringr) # Tools for cleaning up text
library(rvest) # Tools for scraping
donotcall <- read_csv("https://www.ftc.gov/sites/default/files/dnc_complaint_numbers_2018-07-02-06.csv")
View(donotcall)
file.info(donotcall)
object.size(donotcall)
donotcall <- read_csv("https://www.ssa.gov/disability/data/SSA-SA-FYWL.csv")
View(donotcall)
speeding <- read_csv("https://raw.githubusercontent.com/dhmontgomery/r-data-for-beginners/master/speedingdata.csv")
ssa <- read_csv("https://www.ssa.gov/disability/data/SSA-SA-FYWL.csv")
View(ssa)
object.size(ssa)
?rvest
download.file(url = "https://www.ssa.gov/disability/data/SSA-SA-FYWL.csv",
destfile = "SSA-SA-FYWL.csv")
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, eval = FALSE)
library(tidyverse) # All sorts of vital tools
library(scales) # Helps make our ggplot graphs prettier
library(stringr) # Tools for cleaning up text
library(rvest) # Tools for scraping
ssa <- read_csv("SSA-SA-FYWL.csv")
?unzip
download.file(url = "http://www.newcl.org/data/zipfiles/a1.zip", destfile = "testzip.zip")
download.file(url = "https://www1.toronto.ca/City_Of_Toronto/Information_Technology/Open_Data/Data_Sets/Assets/Files/fire_stns.zip",
destfile = "testzip.zip")
download.file(url = "https://www.bls.gov/tus/special.requests/atusact_0315.zip",
destfile = "testzip.zip")
download.file(url = "http://api.worldbank.org/v2/en/country/gbr?downloadformat=csv",
destfile = "testzip1.zip")
download.file(url = "http://api.worldbank.org/v2/en/country/gbr?downloadformat=csv",
destfile = "testzip.zip")
remove.file(
"testzip1.zip"
)
file.remove(
"testzip1.zip"
)
unzip("testzip.zip")
dir()
download.file(url = "http://api.worldbank.org/v2/en/country/gbr?downloadformat=csv",
destfile = "testdata/testzip.zip")
dir.create("testdata")
download.file(url = "http://api.worldbank.org/v2/en/country/gbr?downloadformat=csv",
destfile = "testdata/testzip.zip")
unzip("testdata/testzip.zip") # Unzips the data
dir("testdata")
unzip("testdata/testzip.zip",
exdir = "testdata") # Unzips the data
dir("testdata")
testdata <- read_csv("API_GBR_DS2_en_csv_v2_10402095.csv")
testdata <- read_csv("testdata/API_GBR_DS2_en_csv_v2_10402095.csv")
View(testdata)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # All sorts of vital tools
library(scales) # Helps make our ggplot graphs prettier
library(stringr) # Tools for cleaning up text
library(rvest) # Tools for scraping
file.remove("testdata/testzip.zip") # Remove the unneeded ZIP
temp <- tempfile() # Creates a temporary file and stores a link to it in R in the object `temp`
download.file(url = "http://api.worldbank.org/v2/en/country/gbr?downloadformat=csv",
destfile = temp)
dir.create("testdata2")
dir.create("testdata2")
unzip(temp, exdir = "testdata2")
unzip(temp, exdir = "testdata2")
unzip(temp, exdir = "testdata2")
?setwd
url <- "https://en.wikipedia.org/wiki/World_Series_television_ratings"
ratings <- url %>%
read_html()
View(ratings)
ratings$node
ratings$node[[1]]
ratings[[1]]
ratings$doc
str(ratings)
ratings <- url %>% # Start with our URL
read_html() %>% # Load the HTML from that URL into R
html_nodes(xpath='//*[@id="mw-content-text"]/div/table[2]')
View(ratings)
View(ratings)
ratings[[1]]
ratings[[1]][1]
ratings <- url %>%
read_html() %>%
html_nodes(xpath='//*[@id="mw-content-text"]/div/table[2]') %>% # Point to the right table on the page via its xpath ID
html_table(fill = TRUE)# Fill out any missing cells
View(ratings)
View(ratings)
ratings <- url %>%
read_html() %>%
html_nodes(xpath='//*[@id="mw-content-text"]/div/table[2]') %>% # Point to the right table on the page via its xpath ID
html_table(fill = TRUE) %>% # Fill out any missing cells
`[[`(1) # Extract the data frame from the list created above
View(ratings)
?html_table
View(ratings)
ratings_clean <- ratings %>%
filter(Results != "Canceled due to the MLB strike") %>% # Remove the cancelled 1994 World Series
ratings_clean <- ratings %>%
filter(Results != "Canceled due to the MLB strike") # Remove the cancelled 1994 World Series
View(ratings_clean)
ratings_clean <- ratings %>%
filter(Results != "Canceled due to the MLB strike") %>% # Remove the cancelled 1994 World Series
select(-`Avg.`) # Drop average column
ratings_clean <- ratings %>%
filter(Results != "Canceled due to the MLB strike") %>% # Remove the cancelled 1994 World Series
select(-`Avg.`) %>% # Drop average column
gather("game", "viewers", 4:10) # Reshape data
?spread
?gather
ratings_clean <- ratings %>%
filter(Results != "Canceled due to the MLB strike") %>% # Remove the cancelled 1994 World Series
select(-`Avg.`) %>% # Drop average column
gather(key = "game", value = "viewers", 4:10) %>% # Reshape data
spread(key = game, value = viewers)
View(ratings_clean)
ratings_clean <- ratings %>%
filter(Results != "Canceled due to the MLB strike") %>% # Remove the cancelled 1994 World Series
select(-`Avg.`) %>% # Drop average column
gather(key = "game", value = "viewers", 4:10) # Reshape data
View(ratings_clean)
ratings_clean <- ratings %>%
filter(Results != "Canceled due to the MLB strike") %>% # Remove the cancelled 1994 World Series
select(-`Avg.`) %>% # Drop average column
gather(key = "game", value = "viewers", 4:10) %>% # Reshape data
filter(viewers != "No Game")
ratings_clean <- ratings %>%
filter(Results != "Canceled due to the MLB strike") %>% # Remove the cancelled 1994 World Series
select(-`Avg.`) %>% # Drop average column
gather(key = "game", value = "viewers", 4:10)
ratings_clean <- ratings %>%
filter(Results != "Canceled due to the MLB strike") %>% # Remove the cancelled 1994 World Series
select(-`Avg.`) %>% # Drop average column
gather(key = "game", value = "viewers", 4:10) %>% # Reshape data
filter(viewers != "No Game")
ratings_clean <- ratings %>%
filter(Results != "Canceled due to the MLB strike") %>% # Remove the cancelled 1994 World Series
select(-`Avg.`) %>% # Drop average column
gather(key = "game", value = "viewers", 4:10) %>% # Reshape data
filter(viewers != "No Game") %>% # Remove "No Game" rows
mutate(viewers = viewers %>% str_remove_all("\\[[0-9]{1,2}\\]")) %>% # Remove footnoted brackets
ratings_clean <- ratings %>%
filter(Results != "Canceled due to the MLB strike") %>% # Remove the cancelled 1994 World Series
select(-`Avg.`) %>% # Drop average column
gather(key = "game", value = "viewers", 4:10) %>% # Reshape data
filter(viewers != "No Game") %>% # Remove "No Game" rows
mutate(viewers = str_remove_all(viewers, "\\[[0-9]{1,2}\\]")) # Remove footnoted brackets
?str_remove_all
mutate(viewers = str_remove_all(viewers, " Mviewers)) # Remove footnoted brackets
ratings_clean <- ratings %>%
filter(Results != "Canceled due to the MLB strike") %>% # Remove the cancelled 1994 World Series
select(-`Avg.`) %>% # Drop average column
gather(key = "game", value = "viewers", 4:10) %>% # Reshape data
filter(viewers != "No Game") %>% # Remove "No Game" rows
mutate(viewers = str_remove_all(viewers, " Mviewers")) # Remove footnoted brackets
ssa <- read_csv("https://raw.githubusercontent.com/rdrr1990/bigKRLS/master/examples/data2016GE.csv")
View(ssa)
ratings_clean <- ratings %>%
filter(Results != "Canceled due to the MLB strike") %>% # Remove the cancelled 1994 World Series
select(-`Avg.`) %>% # Drop average column
gather(key = "game", value = "viewers", 4:10) %>% # Reshape data
filter(viewers != "No Game") %>% # Remove "No Game" rows
mutate(viewers = str_remove_all(viewers, "\\[[0-9]{1,2}\\]")) # Remove footnoted brackets
ratings_clean <- ratings %>%
filter(Results != "Canceled due to the MLB strike") %>% # Remove the cancelled 1994 World Series
select(-`Avg.`) %>% # Drop average column
gather(key = "game", value = "viewers", 4:10) %>% # Reshape data
filter(viewers != "No Game") %>% # Remove "No Game" rows
mutate(viewers = str_remove_all(viewers, "\\[[0-9]{1,2}\\]")) %>% # Remove footnoted brackets with regex magic
separate(viewers, c("rating", "share"), sep = "/", fill = "right", convert = TRUE) # Separate on the "/"
?separate
ratings_clean <- ratings %>%
filter(Results != "Canceled due to the MLB strike") %>% # Remove the cancelled 1994 World Series
select(-`Avg.`) %>% # Drop average column
gather(key = "game", value = "viewers", 4:10) %>% # Reshape data
filter(viewers != "No Game") %>% # Remove "No Game" rows
mutate(viewers = str_remove_all(viewers, pattern = "\\[[0-9]{1,2}\\]")) %>% # Remove footnoted brackets with regex magic
separate(viewers, sep = "/", into = c("rating", "share"), convert = TRUE) %>% # Separate on the "/"
separate(share, c("share", "viewers"), convert = TRUE, sep = "\\(")
ratings_clean <- ratings %>%
filter(Results != "Canceled due to the MLB strike") %>% # Remove the cancelled 1994 World Series
select(-`Avg.`) %>% # Drop average column
gather(key = "game", value = "viewers", 4:10) %>% # Reshape data
filter(viewers != "No Game") %>% # Remove "No Game" rows
mutate(viewers = str_remove_all(viewers, pattern = "\\[[0-9]{1,2}\\]")) %>% # Remove footnoted brackets with regex magic
separate(viewers, sep = "/", into = c("rating", "share"), convert = TRUE) %>% # Separate on the "/"
separate(share, c("share", "viewers"), convert = TRUE, sep = "\\(") %>% # Separate on the open parentheses
separate(viewers, c("viewers"), sep = " ", extra = "drop", convert = TRUE)
ratings_clean <- ratings %>%
filter(Results != "Canceled due to the MLB strike") %>% # Remove the cancelled 1994 World Series
select(-`Avg.`) %>% # Drop average column
gather(key = "game", value = "viewers", 4:10) %>% # Reshape data
filter(viewers != "No Game") %>% # Remove "No Game" rows
mutate(viewers = str_remove_all(viewers, pattern = "\\[[0-9]{1,2}\\]")) %>% # Remove footnoted brackets with regex magic
separate(viewers, sep = "/", into = c("rating", "share"), convert = TRUE) %>% # Separate on the "/"
separate(share, sep = "\\(", into = c("share", "viewers"), convert = TRUE) %>% # Separate on the open parentheses
separate(viewers, sep = " ", into = c("viewers"), extra = "drop", convert = TRUE) %>% # Separate on the first space, dropping extras
separate(viewers, sep = "\\–", into = c("viewers"), extra = "drop", convert = TRUE) # One year's rating was given as a range. Take the lower number
ggplot(ratings, aes(Year, viewers)) +
geom_point(size = 2) + # No smoothing surve. No colors
labs(title = "World Series ratings (1984-present)",
subtitle = "By David H. Montgomery, dhmontgomery.com",
caption = "Data from wikipedia.org/wiki/World_Series_television_ratings",
y = "Millions of viewers") +
theme_bw() +
facet_wrap(vars(game), nrow = 1) # Facet the chart by game
ggplot(ratings_clean, aes(Year, viewers)) +
geom_point(size = 2) + # No smoothing surve. No colors
labs(title = "World Series ratings (1984-present)",
subtitle = "By David H. Montgomery, dhmontgomery.com",
caption = "Data from wikipedia.org/wiki/World_Series_television_ratings",
y = "Millions of viewers") +
theme_bw() +
facet_wrap(vars(game), nrow = 1) # Facet the chart by game
